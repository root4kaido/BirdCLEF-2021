{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c1a97e",
   "metadata": {
    "papermill": {
     "duration": 0.016618,
     "end_time": "2021-04-05T14:45:10.972048",
     "exception": false,
     "start_time": "2021-04-05T14:45:10.955430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## About this notebook\n",
    "\n",
    "In this notebook, I will show the way to train the model used here:\n",
    "https://www.kaggle.com/hidehisaarai1213/pytorch-inference-birdclef2021-starter\n",
    "\n",
    "Note that by default this notebook will only train the model one epoch, but [the weight](https://www.kaggle.com/hidehisaarai1213/birdclef2021-effnetb0-starter-weight) I used was obtained after 31epochs of training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6880b",
   "metadata": {
    "papermill": {
     "duration": 0.015427,
     "end_time": "2021-04-05T14:45:11.003053",
     "exception": false,
     "start_time": "2021-04-05T14:45:10.987626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c986a42",
   "metadata": {
    "papermill": {
     "duration": 8.171432,
     "end_time": "2021-04-05T14:45:35.970129",
     "exception": false,
     "start_time": "2021-04-05T14:45:27.798697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting catalyst==20.12\n",
      "  Downloading catalyst-20.12-py2.py3-none-any.whl (490 kB)\n",
      "\u001b[K     |████████████████████████████████| 490 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboardX>=2.1.0\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst==20.12) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.12) (4.60.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst==20.12) (20.9)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /home/user/.local/lib/python3.6/site-packages (from catalyst==20.12) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.1.0 in /home/user/.local/lib/python3.6/site-packages (from catalyst==20.12) (1.7.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/user/.local/lib/python3.6/site-packages (from tensorboardX>=2.1.0->catalyst==20.12) (3.17.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/user/.local/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX>=2.1.0->catalyst==20.12) (1.15.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.12) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/user/.local/lib/python3.6/site-packages (from torch>=1.1.0->catalyst==20.12) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst==20.12) (2.2.2)\n",
      "Installing collected packages: tensorboardX, catalyst\n",
      "\u001b[33m  WARNING: The scripts catalyst-contrib and catalyst-dl are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed catalyst-20.12 tensorboardX-2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install catalyst==20.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec2922",
   "metadata": {
    "papermill": {
     "duration": 0.022036,
     "end_time": "2021-04-05T14:45:36.016281",
     "exception": false,
     "start_time": "2021-04-05T14:45:35.994245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be76251",
   "metadata": {
    "papermill": {
     "duration": 6.454862,
     "end_time": "2021-04-05T14:45:42.493114",
     "exception": false,
     "start_time": "2021-04-05T14:45:36.038252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from catalyst.core import Callback, CallbackOrder, IRunner\n",
    "from catalyst.dl import Runner, SupervisedRunner\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from timm.models.layers import SelectAdaptivePool2d\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchlibrosa.augmentation import SpecAugmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe08f8",
   "metadata": {
    "papermill": {
     "duration": 0.022059,
     "end_time": "2021-04-05T14:45:42.537613",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.515554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f28b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/BirdCLEF2021/data/\")\n",
    "MAIN_DATA_DIR = DATA_DIR / 'birdclef-2021'\n",
    "OUTPUT_DIR = Path('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a90ba0",
   "metadata": {
    "papermill": {
     "duration": 0.05012,
     "end_time": "2021-04-05T14:45:42.610513",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.560393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ######################\n",
    "    # Globals #\n",
    "    ######################\n",
    "    seed = 1213\n",
    "    epochs = 35\n",
    "    train = True\n",
    "    folds = [0]\n",
    "    img_size = 224\n",
    "    main_metric = \"epoch_f1_at_05\"\n",
    "    minimize_metric = False\n",
    "\n",
    "    ######################\n",
    "    # Data #\n",
    "    ######################\n",
    "    train_datadir = MAIN_DATA_DIR / 'train_short_audio'\n",
    "    train_csv = MAIN_DATA_DIR / 'train_metadata.csv'\n",
    "    train_soundscape = MAIN_DATA_DIR / 'train_soundscape_labels.csv'\n",
    "\n",
    "    ######################\n",
    "    # Dataset #\n",
    "    ######################\n",
    "    transforms = {\n",
    "        \"train\": [{\"name\": \"Normalize\"}],\n",
    "        \"valid\": [{\"name\": \"Normalize\"}]\n",
    "    }\n",
    "    period = 20\n",
    "    n_mels = 128\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    sample_rate = 32000\n",
    "    melspectrogram_parameters = {\n",
    "        \"n_mels\": 224,\n",
    "        \"fmin\": 20,\n",
    "        \"fmax\": 16000\n",
    "    }\n",
    "\n",
    "    target_columns = [\n",
    "        'acafly', 'acowoo', 'aldfly', 'ameavo', 'amecro',\n",
    "        'amegfi', 'amekes', 'amepip', 'amered', 'amerob',\n",
    "        'amewig', 'amtspa', 'andsol1', 'annhum', 'astfly',\n",
    "        'azaspi1', 'babwar', 'baleag', 'balori', 'banana',\n",
    "        'banswa', 'banwre1', 'barant1', 'barswa', 'batpig1',\n",
    "        'bawswa1', 'bawwar', 'baywre1', 'bbwduc', 'bcnher',\n",
    "        'belkin1', 'belvir', 'bewwre', 'bkbmag1', 'bkbplo',\n",
    "        'bkbwar', 'bkcchi', 'bkhgro', 'bkmtou1', 'bknsti', 'blbgra1',\n",
    "        'blbthr1', 'blcjay1', 'blctan1', 'blhpar1', 'blkpho',\n",
    "        'blsspa1', 'blugrb1', 'blujay', 'bncfly', 'bnhcow', 'bobfly1',\n",
    "        'bongul', 'botgra', 'brbmot1', 'brbsol1', 'brcvir1', 'brebla',\n",
    "        'brncre', 'brnjay', 'brnthr', 'brratt1', 'brwhaw', 'brwpar1',\n",
    "        'btbwar', 'btnwar', 'btywar', 'bucmot2', 'buggna', 'bugtan',\n",
    "        'buhvir', 'bulori', 'burwar1', 'bushti', 'butsal1', 'buwtea',\n",
    "        'cacgoo1', 'cacwre', 'calqua', 'caltow', 'cangoo', 'canwar',\n",
    "        'carchi', 'carwre', 'casfin', 'caskin', 'caster1', 'casvir',\n",
    "        'categr', 'ccbfin', 'cedwax', 'chbant1', 'chbchi', 'chbwre1',\n",
    "        'chcant2', 'chispa', 'chswar', 'cinfly2', 'clanut', 'clcrob',\n",
    "        'cliswa', 'cobtan1', 'cocwoo1', 'cogdov', 'colcha1', 'coltro1',\n",
    "        'comgol', 'comgra', 'comloo', 'commer', 'compau', 'compot1',\n",
    "        'comrav', 'comyel', 'coohaw', 'cotfly1', 'cowscj1', 'cregua1',\n",
    "        'creoro1', 'crfpar', 'cubthr', 'daejun', 'dowwoo', 'ducfly', 'dusfly',\n",
    "        'easblu', 'easkin', 'easmea', 'easpho', 'eastow', 'eawpew', 'eletro',\n",
    "        'eucdov', 'eursta', 'fepowl', 'fiespa', 'flrtan1', 'foxspa', 'gadwal',\n",
    "        'gamqua', 'gartro1', 'gbbgul', 'gbwwre1', 'gcrwar', 'gilwoo',\n",
    "        'gnttow', 'gnwtea', 'gocfly1', 'gockin', 'gocspa', 'goftyr1',\n",
    "        'gohque1', 'goowoo1', 'grasal1', 'grbani', 'grbher3', 'grcfly',\n",
    "        'greegr', 'grekis', 'grepew', 'grethr1', 'gretin1', 'greyel',\n",
    "        'grhcha1', 'grhowl', 'grnher', 'grnjay', 'grtgra', 'grycat',\n",
    "        'gryhaw2', 'gwfgoo', 'haiwoo', 'heptan', 'hergul', 'herthr',\n",
    "        'herwar', 'higmot1', 'hofwoo1', 'houfin', 'houspa', 'houwre',\n",
    "        'hutvir', 'incdov', 'indbun', 'kebtou1', 'killde', 'labwoo', 'larspa',\n",
    "        'laufal1', 'laugul', 'lazbun', 'leafly', 'leasan', 'lesgol', 'lesgre1',\n",
    "        'lesvio1', 'linspa', 'linwoo1', 'littin1', 'lobdow', 'lobgna5', 'logshr',\n",
    "        'lotduc', 'lotman1', 'lucwar', 'macwar', 'magwar', 'mallar3', 'marwre',\n",
    "        'mastro1', 'meapar', 'melbla1', 'monoro1', 'mouchi', 'moudov', 'mouela1',\n",
    "        'mouqua', 'mouwar', 'mutswa', 'naswar', 'norcar', 'norfli', 'normoc', 'norpar',\n",
    "        'norsho', 'norwat', 'nrwswa', 'nutwoo', 'oaktit', 'obnthr1', 'ocbfly1',\n",
    "        'oliwoo1', 'olsfly', 'orbeup1', 'orbspa1', 'orcpar', 'orcwar', 'orfpar',\n",
    "        'osprey', 'ovenbi1', 'pabspi1', 'paltan1', 'palwar', 'pasfly', 'pavpig2',\n",
    "        'phivir', 'pibgre', 'pilwoo', 'pinsis', 'pirfly1', 'plawre1', 'plaxen1',\n",
    "        'plsvir', 'plupig2', 'prowar', 'purfin', 'purgal2', 'putfru1', 'pygnut',\n",
    "        'rawwre1', 'rcatan1', 'rebnut', 'rebsap', 'rebwoo', 'redcro', 'reevir1',\n",
    "        'rehbar1', 'relpar', 'reshaw', 'rethaw', 'rewbla', 'ribgul', 'rinkin1',\n",
    "        'roahaw', 'robgro', 'rocpig', 'rotbec', 'royter1', 'rthhum', 'rtlhum',\n",
    "        'ruboro1', 'rubpep1', 'rubrob', 'rubwre1', 'ruckin', 'rucspa1', 'rucwar',\n",
    "        'rucwar1', 'rudpig', 'rudtur', 'rufhum', 'rugdov', 'rumfly1', 'runwre1',\n",
    "        'rutjac1', 'saffin', 'sancra', 'sander', 'savspa', 'saypho', 'scamac1',\n",
    "        'scatan', 'scbwre1', 'scptyr1', 'scrtan1', 'semplo', 'shicow', 'sibtan2',\n",
    "        'sinwre1', 'sltred', 'smbani', 'snogoo', 'sobtyr1', 'socfly1', 'solsan',\n",
    "        'sonspa', 'soulap1', 'sposan', 'spotow', 'spvear1', 'squcuc1', 'stbori',\n",
    "        'stejay', 'sthant1', 'sthwoo1', 'strcuc1', 'strfly1', 'strsal1', 'stvhum2',\n",
    "        'subfly', 'sumtan', 'swaspa', 'swathr', 'tenwar', 'thbeup1', 'thbkin',\n",
    "        'thswar1', 'towsol', 'treswa', 'trogna1', 'trokin', 'tromoc', 'tropar',\n",
    "        'tropew1', 'tuftit', 'tunswa', 'veery', 'verdin', 'vigswa', 'warvir',\n",
    "        'wbwwre1', 'webwoo1', 'wegspa1', 'wesant1', 'wesblu', 'weskin', 'wesmea',\n",
    "        'westan', 'wewpew', 'whbman1', 'whbnut', 'whcpar', 'whcsee1', 'whcspa',\n",
    "        'whevir', 'whfpar1', 'whimbr', 'whiwre1', 'whtdov', 'whtspa', 'whwbec1',\n",
    "        'whwdov', 'wilfly', 'willet1', 'wilsni1', 'wiltur', 'wlswar', 'wooduc',\n",
    "        'woothr', 'wrenti', 'y00475', 'yebcha', 'yebela1', 'yebfly', 'yebori1',\n",
    "        'yebsap', 'yebsee1', 'yefgra1', 'yegvir', 'yehbla', 'yehcar1', 'yelgro',\n",
    "        'yelwar', 'yeofly1', 'yerwar', 'yeteup1', 'yetvir']\n",
    "\n",
    "    ######################\n",
    "    # Loaders #\n",
    "    ######################\n",
    "    loader_params = {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"num_workers\": 2,\n",
    "            \"shuffle\": True,\n",
    "            'pin_memory': True,\n",
    "            'drop_last': True,\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 1,\n",
    "            \"num_workers\": 2,\n",
    "            \"shuffle\": False,\n",
    "            'pin_memory': True,\n",
    "            'drop_last': True,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ######################\n",
    "    # Split #\n",
    "    ######################\n",
    "    split = \"StratifiedKFold\"\n",
    "    split_params = {\n",
    "        \"n_splits\": 5,\n",
    "        \"shuffle\": True,\n",
    "        \"random_state\": 1213\n",
    "    }\n",
    "\n",
    "    ######################\n",
    "    # Model #\n",
    "    ######################\n",
    "    base_model_name = \"tf_efficientnet_b0_ns\"\n",
    "    pooling = \"max\"\n",
    "    pretrained = True\n",
    "    num_classes = 397\n",
    "    in_channels = 1\n",
    "\n",
    "    ######################\n",
    "    # Criterion #\n",
    "    ######################\n",
    "    loss_name = \"BCEFocal2WayLoss\"\n",
    "    loss_params: dict = {}\n",
    "\n",
    "    ######################\n",
    "    # Optimizer #\n",
    "    ######################\n",
    "    optimizer_name = \"Adam\"\n",
    "    base_optimizer = \"Adam\"\n",
    "    optimizer_params = {\n",
    "        \"lr\": 0.001\n",
    "    }\n",
    "    # For SAM optimizer\n",
    "    base_optimizer = \"Adam\"\n",
    "\n",
    "    ######################\n",
    "    # Scheduler #\n",
    "    ######################\n",
    "    scheduler_name = \"CosineAnnealingLR\"\n",
    "    scheduler_params = {\n",
    "        \"T_max\": 10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf99b17",
   "metadata": {
    "papermill": {
     "duration": 0.028749,
     "end_time": "2021-04-05T14:45:42.661399",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.632650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this notebook is by default run on debug mode (only train one epoch).\n",
    "# If you'd like to get the results on par with that of inference notebook, you'll need to train the model around 30 epochs\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    CFG.epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f154d7d",
   "metadata": {
    "papermill": {
     "duration": 0.021935,
     "end_time": "2021-04-05T14:45:42.705403",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.683468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8aa821",
   "metadata": {
    "papermill": {
     "duration": 0.031953,
     "end_time": "2021-04-05T14:45:42.759437",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.727484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e041f50",
   "metadata": {
    "papermill": {
     "duration": 0.022258,
     "end_time": "2021-04-05T14:45:42.803917",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.781659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset and Data Augmentations\n",
    "\n",
    "In this section, I define dataset that crops 20 second chunk. The output of this dataset is a pair of waveform and corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdca0279",
   "metadata": {
    "papermill": {
     "duration": 0.035774,
     "end_time": "2021-04-05T14:45:42.861885",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.826111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WaveformDataset(torchdata.Dataset):\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 datadir: Path,\n",
    "                 img_size=224,\n",
    "                 waveform_transforms=None,\n",
    "                 period=20,\n",
    "                 validation=False):\n",
    "        self.df = df\n",
    "        self.datadir = datadir\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.period = period\n",
    "        self.validation = validation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.loc[idx, :]\n",
    "        wav_name = sample[\"filename\"]\n",
    "        ebird_code = sample[\"primary_label\"]\n",
    "\n",
    "        y, sr = sf.read(self.datadir / ebird_code / wav_name)\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        if len_y < effective_length:\n",
    "            new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "            if not self.validation:\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "            else:\n",
    "                start = 0\n",
    "            new_y[start:start + len_y] = y\n",
    "            y = new_y.astype(np.float32)\n",
    "        elif len_y > effective_length:\n",
    "            if not self.validation:\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "            else:\n",
    "                start = 0\n",
    "            y = y[start:start + effective_length].astype(np.float32)\n",
    "        else:\n",
    "            y = y.astype(np.float32)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        labels = np.zeros(len(CFG.target_columns), dtype=float)\n",
    "        labels[CFG.target_columns.index(ebird_code)] = 1.0\n",
    "\n",
    "        return {\n",
    "            \"image\": y,\n",
    "            \"targets\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709461fe",
   "metadata": {
    "papermill": {
     "duration": 0.033136,
     "end_time": "2021-04-05T14:45:42.917306",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.884170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(phase: str):\n",
    "    transforms = CFG.transforms\n",
    "    if transforms is None:\n",
    "        return None\n",
    "    else:\n",
    "        if transforms[phase] is None:\n",
    "            return None\n",
    "        trns_list = []\n",
    "        for trns_conf in transforms[phase]:\n",
    "            trns_name = trns_conf[\"name\"]\n",
    "            trns_params = {} if trns_conf.get(\"params\") is None else \\\n",
    "                trns_conf[\"params\"]\n",
    "            if globals().get(trns_name) is not None:\n",
    "                trns_cls = globals()[trns_name]\n",
    "                trns_list.append(trns_cls(**trns_params))\n",
    "\n",
    "        if len(trns_list) > 0:\n",
    "            return Compose(trns_list)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "class Normalize:\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y * 1 / max_vol\n",
    "        return np.asfortranarray(y_vol)\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff3ad6",
   "metadata": {
    "papermill": {
     "duration": 0.022645,
     "end_time": "2021-04-05T14:45:42.962399",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.939754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "In this notebook, I will use a model for SED task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa4c4cd5",
   "metadata": {
    "papermill": {
     "duration": 0.063124,
     "end_time": "2021-04-05T14:45:43.048224",
     "exception": false,
     "start_time": "2021-04-05T14:45:42.985100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n",
    "           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(\n",
    "                self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1. / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f\"(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n",
    "        super().__init__()\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n",
    "                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n",
    "                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n",
    "                                               freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.spectrogram_extractor(input)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff1468",
   "metadata": {
    "papermill": {
     "duration": 0.022538,
     "end_time": "2021-04-05T14:45:43.093668",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.071130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7765318e",
   "metadata": {
    "papermill": {
     "duration": 0.034089,
     "end_time": "2021-04-05T14:45:43.150351",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.116262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/213075\n",
    "class BCEFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n",
    "        probas = torch.sigmoid(preds)\n",
    "        loss = targets * self.alpha * \\\n",
    "            (1. - probas)**self.gamma * bce_loss + \\\n",
    "            (1. - targets) * probas**self.gamma * bce_loss\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class BCEFocal2WayLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1], class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.focal = BCEFocalLoss()\n",
    "\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"logit\"]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        loss = self.focal(input_, target)\n",
    "        aux_loss = self.focal(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * loss + self.weights[1] * aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae271ba1",
   "metadata": {
    "papermill": {
     "duration": 0.030366,
     "end_time": "2021-04-05T14:45:43.203589",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.173223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "__CRITERIONS__ = {\n",
    "    \"BCEFocalLoss\": BCEFocalLoss,\n",
    "    \"BCEFocal2WayLoss\": BCEFocal2WayLoss\n",
    "}\n",
    "\n",
    "\n",
    "def get_criterion():\n",
    "    if hasattr(nn, CFG.loss_name):\n",
    "        return nn.__getattribute__(CFG.loss_name)(**CFG.loss_params)\n",
    "    elif __CRITERIONS__.get(CFG.loss_name) is not None:\n",
    "        return __CRITERIONS__[CFG.loss_name](**CFG.loss_params)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7b146",
   "metadata": {
    "papermill": {
     "duration": 0.022794,
     "end_time": "2021-04-05T14:45:43.249240",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.226446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Utilities\n",
    "\n",
    "Optimizers, Schedulers, Callbacks and the Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e0b94e",
   "metadata": {
    "papermill": {
     "duration": 0.032503,
     "end_time": "2021-04-05T14:45:43.304853",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.272350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom optimizer\n",
    "__OPTIMIZERS__ = {}\n",
    "\n",
    "\n",
    "def get_optimizer(model: nn.Module):\n",
    "    optimizer_name = CFG.optimizer_name\n",
    "    if optimizer_name == \"SAM\":\n",
    "        base_optimizer_name = CFG.base_optimizer\n",
    "        if __OPTIMIZERS__.get(base_optimizer_name) is not None:\n",
    "            base_optimizer = __OPTIMIZERS__[base_optimizer_name]\n",
    "        else:\n",
    "            base_optimizer = optim.__getattribute__(base_optimizer_name)\n",
    "        return SAM(model.parameters(), base_optimizer, **CFG.optimizer_params)\n",
    "\n",
    "    if __OPTIMIZERS__.get(optimizer_name) is not None:\n",
    "        return __OPTIMIZERS__[optimizer_name](model.parameters(),\n",
    "                                              **CFG.optimizer_params)\n",
    "    else:\n",
    "        return optim.__getattribute__(optimizer_name)(model.parameters(),\n",
    "                                                      **CFG.optimizer_params)\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer):\n",
    "    scheduler_name = CFG.scheduler_name\n",
    "\n",
    "    if scheduler_name is None:\n",
    "        return\n",
    "    else:\n",
    "        return optim.lr_scheduler.__getattribute__(scheduler_name)(\n",
    "            optimizer, **CFG.scheduler_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da188672",
   "metadata": {
    "papermill": {
     "duration": 0.045586,
     "end_time": "2021-04-05T14:45:43.373306",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.327720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SchedulerCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(CallbackOrder.Scheduler)\n",
    "\n",
    "    def on_loader_end(self, state: IRunner):\n",
    "        lr = state.scheduler.get_last_lr()\n",
    "        state.epoch_metrics[\"lr\"] = lr[0]\n",
    "        if state.is_train_loader:\n",
    "            state.scheduler.step()\n",
    "\n",
    "\n",
    "class SampleF1Callback(Callback):\n",
    "    def __init__(self,\n",
    "                 input_key: str = \"targets\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 prefix: str = \"f1\",\n",
    "                 threshold=0.5):\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "\n",
    "        self.input_key = input_key\n",
    "        self.output_key = output_key\n",
    "        self.prefix = prefix\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_loader_start(self, state: IRunner):\n",
    "        self.prediction: List[np.ndarray] = []\n",
    "        self.target: List[np.ndarray] = []\n",
    "\n",
    "    def on_batch_end(self, state: IRunner):\n",
    "        targ = state.input[self.input_key].detach().cpu().numpy()\n",
    "        out = state.output[self.output_key]\n",
    "\n",
    "        clipwise_output = out[\"clipwise_output\"].detach().cpu().numpy()\n",
    "\n",
    "        self.prediction.append(clipwise_output)\n",
    "        self.target.append(targ)\n",
    "\n",
    "        y_pred = clipwise_output > self.threshold\n",
    "        score = metrics.f1_score(targ, y_pred, average=\"samples\")\n",
    "\n",
    "        state.batch_metrics[self.prefix] = score\n",
    "\n",
    "    def on_loader_end(self, state: IRunner):\n",
    "        y_pred = np.concatenate(self.prediction, axis=0) > self.threshold\n",
    "        y_true = np.concatenate(self.target, axis=0)\n",
    "        score = metrics.f1_score(y_true, y_pred, average=\"samples\")\n",
    "\n",
    "        state.loader_metrics[self.prefix] = score\n",
    "        if state.is_valid_loader:\n",
    "            state.epoch_metrics[state.valid_loader + \"_epoch_\" +\n",
    "                                self.prefix] = score\n",
    "        else:\n",
    "            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score\n",
    "\n",
    "\n",
    "class mAPCallback(Callback):\n",
    "    def __init__(self,\n",
    "                 input_key: str = \"targets\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 model_output_key: str = \"clipwise_output\",\n",
    "                 prefix: str = \"mAP\"):\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "        self.input_key = input_key\n",
    "        self.output_key = output_key\n",
    "        self.model_output_key = model_output_key\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def on_loader_start(self, state: IRunner):\n",
    "        self.prediction: List[np.ndarray] = []\n",
    "        self.target: List[np.ndarray] = []\n",
    "\n",
    "    def on_batch_end(self, state: IRunner):\n",
    "        targ = state.input[self.input_key].detach().cpu().numpy()\n",
    "        out = state.output[self.output_key]\n",
    "\n",
    "        clipwise_output = out[self.model_output_key].detach().cpu().numpy()\n",
    "\n",
    "        self.prediction.append(clipwise_output)\n",
    "        self.target.append(targ)\n",
    "\n",
    "        try:\n",
    "            score = metrics.average_precision_score(\n",
    "                targ, clipwise_output, average=None)\n",
    "        except ValueError:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        score = np.nan_to_num(score).mean()\n",
    "        state.batch_metrics[self.prefix] = score\n",
    "\n",
    "    def on_loader_end(self, state: IRunner):\n",
    "        y_pred = np.concatenate(self.prediction, axis=0)\n",
    "        y_true = np.concatenate(self.target, axis=0)\n",
    "        score = metrics.average_precision_score(y_true, y_pred, average=None)\n",
    "        score = np.nan_to_num(score).mean()\n",
    "        state.loader_metrics[self.prefix] = score\n",
    "        if state.is_valid_loader:\n",
    "            state.epoch_metrics[state.valid_loader + \"_epoch_\" +\n",
    "                                self.prefix] = score\n",
    "        else:\n",
    "            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score\n",
    "\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        SampleF1Callback(prefix=\"f1_at_05\", threshold=0.5),\n",
    "        SampleF1Callback(prefix=\"f1_at_03\", threshold=0.3),\n",
    "        SampleF1Callback(prefix=\"f1_at_07\", threshold=0.7),\n",
    "        mAPCallback()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf7af4e",
   "metadata": {
    "papermill": {
     "duration": 0.029786,
     "end_time": "2021-04-05T14:45:43.426124",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.396338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_runner(device: torch.device):\n",
    "    return SupervisedRunner(device=device, input_key=\"image\", input_target_key=\"targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4ef6a",
   "metadata": {
    "papermill": {
     "duration": 0.023088,
     "end_time": "2021-04-05T14:45:43.472495",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.449407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c00e3921",
   "metadata": {
    "papermill": {
     "duration": 0.031582,
     "end_time": "2021-04-05T14:45:43.527513",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.495931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logdir = Path(\"out\")\n",
    "logdir.mkdir(exist_ok=True, parents=True)\n",
    "if (logdir / \"train.log\").exists():\n",
    "    os.remove(logdir / \"train.log\")\n",
    "logger = init_logger(log_file=logdir / \"train.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5feff93f",
   "metadata": {
    "papermill": {
     "duration": 0.868244,
     "end_time": "2021-04-05T14:45:44.419003",
     "exception": false,
     "start_time": "2021-04-05T14:45:43.550759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# environment\n",
    "set_seed(CFG.seed)\n",
    "device = get_device()\n",
    "\n",
    "# validation\n",
    "splitter = getattr(model_selection, CFG.split)(**CFG.split_params)\n",
    "\n",
    "# data\n",
    "train = pd.read_csv(CFG.train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a045112",
   "metadata": {
    "papermill": {
     "duration": 4264.412468,
     "end_time": "2021-04-05T15:56:48.856560",
     "exception": false,
     "start_time": "2021-04-05T14:45:44.444092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Fold 0 Training\n",
      "========================================================================================================================\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b0_ns-c0e6a31c.pth\" to /home/user/.cache/torch/hub/checkpoints/tf_efficientnet_b0_ns-c0e6a31c.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/35 * Epoch (train): 100% 8358/8358 [23:39<00:00,  5.89it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.003, mAP=0.013]\n",
      "1/35 * Epoch (valid): 100% 12725/12725 [20:07<00:00, 10.54it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.005, mAP=0.003]    \n",
      "[2021-05-22 16:13:59,456] \n",
      "1/35 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
      "1/35 * Epoch 1 (train): epoch_f1_at_03=0.0038 | epoch_f1_at_05=0.0001 | epoch_f1_at_07=0.000e+00 | epoch_mAP=0.0177 | f1_at_03=0.0038 | f1_at_05=0.0001 | f1_at_07=0.000e+00 | loss=0.0049 | mAP=0.0106\n",
      "1/35 * Epoch 1 (valid): epoch_f1_at_03=0.0482 | epoch_f1_at_05=0.0078 | epoch_f1_at_07=0.0006 | epoch_mAP=0.1900 | f1_at_03=0.0482 | f1_at_05=0.0078 | f1_at_07=0.0006 | loss=0.0026 | mAP=0.0025\n",
      "2/35 * Epoch (train): 100% 8358/8358 [23:50<00:00,  5.84it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.002, mAP=0.013]\n",
      "2/35 * Epoch (valid): 100% 12725/12725 [20:16<00:00, 10.46it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.005, mAP=0.003]    \n",
      "[2021-05-22 16:58:06,250] \n",
      "2/35 * Epoch 2 (_base): lr=0.0009 | momentum=0.9000\n",
      "2/35 * Epoch 2 (train): epoch_f1_at_03=0.0439 | epoch_f1_at_05=0.0042 | epoch_f1_at_07=0.0002 | epoch_mAP=0.1138 | f1_at_03=0.0439 | f1_at_05=0.0042 | f1_at_07=0.0002 | loss=0.0026 | mAP=0.0135\n",
      "2/35 * Epoch 2 (valid): epoch_f1_at_03=0.1172 | epoch_f1_at_05=0.0240 | epoch_f1_at_07=0.0054 | epoch_mAP=0.3413 | f1_at_03=0.1172 | f1_at_05=0.0240 | f1_at_07=0.0054 | loss=0.0023 | mAP=0.0025\n",
      "3/35 * Epoch (train): 100% 8358/8358 [23:51<00:00,  5.84it/s, f1_at_03=0.167, f1_at_05=0.167, f1_at_07=0.000e+00, loss=0.002, mAP=0.011]          \n",
      "3/35 * Epoch (valid): 100% 12725/12725 [20:04<00:00, 10.56it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.005, mAP=0.003]    \n",
      "[2021-05-22 17:42:03,406] \n",
      "3/35 * Epoch 3 (_base): lr=0.0008 | momentum=0.9000\n",
      "3/35 * Epoch 3 (train): epoch_f1_at_03=0.1237 | epoch_f1_at_05=0.0214 | epoch_f1_at_07=0.0019 | epoch_mAP=0.2303 | f1_at_03=0.1237 | f1_at_05=0.0214 | f1_at_07=0.0019 | loss=0.0022 | mAP=0.0140\n",
      "3/35 * Epoch 3 (valid): epoch_f1_at_03=0.2858 | epoch_f1_at_05=0.1101 | epoch_f1_at_07=0.0223 | epoch_mAP=0.4476 | f1_at_03=0.2858 | f1_at_05=0.1101 | f1_at_07=0.0223 | loss=0.0018 | mAP=0.0025\n",
      "4/35 * Epoch (train): 100% 8358/8358 [23:48<00:00,  5.85it/s, f1_at_03=0.667, f1_at_05=0.167, f1_at_07=0.167, loss=8.309e-04, mAP=0.015]        \n",
      "4/35 * Epoch (valid): 100% 12725/12725 [20:13<00:00, 10.49it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.007, mAP=0.003]    \n",
      "[2021-05-22 18:26:06,695] \n",
      "4/35 * Epoch 4 (_base): lr=0.0007 | momentum=0.9000\n",
      "4/35 * Epoch 4 (train): epoch_f1_at_03=0.2070 | epoch_f1_at_05=0.0524 | epoch_f1_at_07=0.0078 | epoch_mAP=0.3415 | f1_at_03=0.2070 | f1_at_05=0.0524 | f1_at_07=0.0078 | loss=0.0020 | mAP=0.0143\n",
      "4/35 * Epoch 4 (valid): epoch_f1_at_03=0.3304 | epoch_f1_at_05=0.1334 | epoch_f1_at_07=0.0332 | epoch_mAP=0.5288 | f1_at_03=0.3304 | f1_at_05=0.1334 | f1_at_07=0.0332 | loss=0.0016 | mAP=0.0025\n",
      "5/35 * Epoch (train): 100% 8358/8358 [23:48<00:00,  5.85it/s, f1_at_03=0.444, f1_at_05=0.167, f1_at_07=0.000e+00, loss=0.001, mAP=0.015]            \n",
      "5/35 * Epoch (valid): 100% 12725/12725 [20:09<00:00, 10.52it/s, f1_at_03=0.000e+00, f1_at_05=0.000e+00, f1_at_07=0.000e+00, loss=0.006, mAP=0.003]    \n",
      "[2021-05-22 19:10:05,483] \n",
      "5/35 * Epoch 5 (_base): lr=0.0005 | momentum=0.9000\n",
      "5/35 * Epoch 5 (train): epoch_f1_at_03=0.2854 | epoch_f1_at_05=0.0932 | epoch_f1_at_07=0.0191 | epoch_mAP=0.4377 | f1_at_03=0.2854 | f1_at_05=0.0932 | f1_at_07=0.0191 | loss=0.0018 | mAP=0.0144\n",
      "5/35 * Epoch 5 (valid): epoch_f1_at_03=0.4142 | epoch_f1_at_05=0.2088 | epoch_f1_at_07=0.0894 | epoch_mAP=0.5648 | f1_at_03=0.4142 | f1_at_05=0.2088 | f1_at_07=0.0894 | loss=0.0016 | mAP=0.0025\n",
      "Early exiting                                                                                                                                   \n",
      "6/35 * Epoch (train):  64% 5371/8358 [15:19<08:20,  5.97it/s, f1_at_03=0.333, f1_at_05=0.167, f1_at_07=0.000e+00, loss=0.002, mAP=0.015]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 826, in run_experiment\n",
      "    self._run_experiment()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 811, in _run_experiment\n",
      "    self._run_stage()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 802, in _run_stage\n",
      "    self._run_epoch()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 796, in _run_epoch\n",
      "    self._run_loader()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 787, in _run_loader\n",
      "    self._run_batch()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 781, in _run_batch\n",
      "    self._run_event(\"on_batch_end\")\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 758, in _run_event\n",
      "    getattr(callback, event)(self)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/callbacks/optimizer.py\", line 274, in on_batch_end\n",
      "    loss.backward()\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/torch/tensor.py\", line 221, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 132, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-81b93f3b0e44>\", line 47, in <module>\n",
      "    minimize_metric=CFG.minimize_metric)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/runners/runner.py\", line 214, in train\n",
      "    distributed_cmd_run(self.run_experiment, distributed)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/utils/scripts.py\", line 178, in distributed_cmd_run\n",
      "    worker_fn(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 829, in run_experiment\n",
      "    self._run_event(\"on_exception\")\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/core/runner.py\", line 758, in _run_event\n",
      "    getattr(callback, event)(self)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/callbacks/checkpoint.py\", line 241, in on_exception\n",
      "    saver_fn=save,\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/catalyst/utils/checkpoint.py\", line 141, in save_checkpoint\n",
      "    saver_fn(checkpoint, filename)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/torch/serialization.py\", line 372, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "  File \"/home/user/.local/lib/python3.6/site-packages/torch/serialization.py\", line 491, in _save\n",
      "    storage._write_file(buf, _should_read_directly(buf), False)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_experiment_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_substring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/callbacks/optimizer.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-81b93f3b0e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmain_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         minimize_metric=CFG.minimize_metric)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/runners/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     ):\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_substring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0msaver_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/utils/checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(checkpoint, logdir, suffix, is_best, is_last, special_suffix, saver_fn)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{logdir}/{suffix}.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0msaver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for i, (trn_idx, val_idx) in enumerate(splitter.split(train, y=train[\"primary_label\"])):\n",
    "    if i not in CFG.folds:\n",
    "        continue\n",
    "    logger.info(\"=\" * 120)\n",
    "    logger.info(f\"Fold {i} Training\")\n",
    "    logger.info(\"=\" * 120)\n",
    "\n",
    "    trn_df = train.loc[trn_idx, :].reset_index(drop=True)\n",
    "    val_df = train.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "    loaders = {\n",
    "        phase: torchdata.DataLoader(\n",
    "            WaveformDataset(\n",
    "                df_,\n",
    "                CFG.train_datadir,\n",
    "                img_size=CFG.img_size,\n",
    "                waveform_transforms=get_transforms(phase),\n",
    "                period=CFG.period,\n",
    "                validation=(phase == \"valid\")\n",
    "            ),\n",
    "            **CFG.loader_params[phase])  # type: ignore\n",
    "        for phase, df_ in zip([\"train\", \"valid\"], [trn_df, val_df])\n",
    "    }\n",
    "\n",
    "    model = TimmSED(\n",
    "        base_model_name=CFG.base_model_name,\n",
    "        pretrained=CFG.pretrained,\n",
    "        num_classes=CFG.num_classes,\n",
    "        in_channels=CFG.in_channels)\n",
    "    criterion = get_criterion()\n",
    "    optimizer = get_optimizer(model)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    callbacks = get_callbacks()\n",
    "    runner = get_runner(device)\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        loaders=loaders,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=CFG.epochs,\n",
    "        verbose=True,\n",
    "        logdir=logdir / f\"fold{i}\",\n",
    "        callbacks=callbacks,\n",
    "        main_metric=CFG.main_metric,\n",
    "        minimize_metric=CFG.minimize_metric)\n",
    "\n",
    "    del model, optimizer, scheduler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e713a6",
   "metadata": {
    "papermill": {
     "duration": 0.912297,
     "end_time": "2021-04-05T15:56:50.677888",
     "exception": false,
     "start_time": "2021-04-05T15:56:49.765591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4309.839023,
   "end_time": "2021-04-05T15:56:55.705989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-05T14:45:05.866966",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
