{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44843dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from timm.models.layers import SelectAdaptivePool2d\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325221eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4eb3d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import src.utils as utils\n",
    "from config_ import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70149f83",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "715051d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f490700",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMISSION:\n",
    "    DATA_DIR = Path(\"../input/\")\n",
    "    OUTPUT_DIR = Path(\"\")\n",
    "else:\n",
    "    DATA_DIR = Path(\"/home/knikaido/work/BirdCLEF2021/data/\")\n",
    "    OUTPUT_DIR = Path('./output/')\n",
    "MAIN_DATA_DIR = DATA_DIR / 'birdclef-2021'\n",
    "\n",
    "TEST = (len(list((MAIN_DATA_DIR / \"test_soundscapes/\").glob(\"*.ogg\"))) != 0)\n",
    "if TEST:\n",
    "    DATADIR = MAIN_DATA_DIR / \"test_soundscapes/\"\n",
    "else:\n",
    "    DATADIR = MAIN_DATA_DIR / \"train_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b4f88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57610_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2782_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26709_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42907_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14473_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54955_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31928_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28933_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21767_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18003_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7843_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10534_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11254_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50878_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26746_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7954_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7019_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20152_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44957_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51010_SSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id\n",
       "0   57610_COR\n",
       "1    2782_SSW\n",
       "2   26709_SSW\n",
       "3   42907_SSW\n",
       "4   14473_SSW\n",
       "5   54955_SSW\n",
       "6   31928_COR\n",
       "7   28933_SSW\n",
       "8   21767_COR\n",
       "9   18003_COR\n",
       "10   7843_SSW\n",
       "11  10534_SSW\n",
       "12  11254_COR\n",
       "13  50878_COR\n",
       "14  26746_COR\n",
       "15   7954_COR\n",
       "16   7019_COR\n",
       "17  20152_SSW\n",
       "18  44957_COR\n",
       "19  51010_SSW"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_audios = list(DATADIR.glob(\"*.ogg\"))\n",
    "all_audio_ids = [\"_\".join(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n",
    "submission_df = pd.DataFrame({\n",
    "    \"row_id\": all_audio_ids\n",
    "})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a658985",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "464822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torchdata.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n",
    "                 waveform_transforms=None):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.waveform_transforms=waveform_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = CFG.sample_rate\n",
    "        sample = self.df.loc[idx, :]\n",
    "        row_id = sample.row_id\n",
    "\n",
    "        end_seconds = int(sample.seconds)\n",
    "        start_seconds = int(end_seconds - 5)\n",
    "\n",
    "        start_index = SR * start_seconds\n",
    "        end_index = SR * end_seconds\n",
    "\n",
    "        y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        return y, row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900539d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(phase: str):\n",
    "    transforms = CFG.transforms\n",
    "    if transforms is None:\n",
    "        return None\n",
    "    else:\n",
    "        if transforms[phase] is None:\n",
    "            return None\n",
    "        trns_list = []\n",
    "        for trns_conf in transforms[phase]:\n",
    "            trns_name = trns_conf[\"name\"]\n",
    "            trns_params = {} if trns_conf.get(\"params\") is None else \\\n",
    "                trns_conf[\"params\"]\n",
    "            if globals().get(trns_name) is not None:\n",
    "                trns_cls = globals()[trns_name]\n",
    "                trns_list.append(trns_cls(**trns_params))\n",
    "\n",
    "        if len(trns_list) > 0:\n",
    "            return Compose(trns_list)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def get_waveform_transforms(config: dict, phase: str):\n",
    "    return get_transforms(config, phase)\n",
    "\n",
    "\n",
    "def get_spectrogram_transforms(config: dict, phase: str):\n",
    "    transforms = config.get('spectrogram_transforms')\n",
    "    if transforms is None:\n",
    "        return None\n",
    "    else:\n",
    "        if transforms[phase] is None:\n",
    "            return None\n",
    "        trns_list = []\n",
    "        for trns_conf in transforms[phase]:\n",
    "            trns_name = trns_conf[\"name\"]\n",
    "            trns_params = {} if trns_conf.get(\"params\") is None else \\\n",
    "                trns_conf[\"params\"]\n",
    "            if hasattr(A, trns_name):\n",
    "                trns_cls = A.__getattribute__(trns_name)\n",
    "                trns_list.append(trns_cls(**trns_params))\n",
    "            else:\n",
    "                trns_cls = globals().get(trns_name)\n",
    "                if trns_cls is not None:\n",
    "                    trns_list.append(trns_cls(**trns_params))\n",
    "\n",
    "        if len(trns_list) > 0:\n",
    "            return A.Compose(trns_list, p=1.0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "class Normalize:\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y * 1 / max_vol\n",
    "        return np.asfortranarray(y_vol)\n",
    "\n",
    "\n",
    "class NewNormalize:\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        y_mm = y - y.mean()\n",
    "        return y_mm / y_mm.abs().max()\n",
    "    \n",
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc59927",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da8efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n",
    "           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(\n",
    "                self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1. / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f\"(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d6b94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.melspectrogramer = torchaudio.transforms.MelSpectrogram(sample_rate=CFG.sample_rate, n_fft=CFG.n_fft, win_length=CFG.n_fft, \n",
    "                                                                     hop_length=CFG.hop_length, f_min=CFG.fmin, \n",
    "                                                                     f_max=CFG.fmax, n_mels=CFG.n_mels, power=1.0)\n",
    "        self.amplituder = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # (batch_size, 1, mel_bins, time_steps)\n",
    "        \n",
    "        x = self.melspectrogramer(input)\n",
    "        x = self.amplituder(x).unsqueeze(1)\n",
    "        frames_num = x.shape[3]\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "#         if self.training:\n",
    "#             x = self.spec_augmenter(x)\n",
    "\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6ad20",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "063b4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_inference(model, path: Path):\n",
    "    if not torch.cuda.is_available():\n",
    "        ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    else:\n",
    "        ckpt = torch.load(path)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b82ad594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner class(pytorch-lighting)\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4daeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0600e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57610_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2782_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26709_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42907_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14473_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54955_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31928_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21767_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18003_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7843_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10534_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11254_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50878_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26746_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7954_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7019_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20152_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44957_COR</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51010_SSW</td>\n",
       "      <td>/home/knikaido/work/BirdCLEF2021/data/birdclef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id                                               path\n",
       "0   57610_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "1    2782_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "2   26709_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "3   42907_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "4   14473_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "5   54955_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "6   31928_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "7   28933_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "8   21767_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "9   18003_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "10   7843_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "11  10534_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "12  11254_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "13  50878_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "14  26746_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "15   7954_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "16   7019_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "17  20152_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "18  44957_COR  /home/knikaido/work/BirdCLEF2021/data/birdclef...\n",
       "19  51010_SSW  /home/knikaido/work/BirdCLEF2021/data/birdclef..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['path'] = all_audios\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e108566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_for_clip(audio_id: str, \n",
    "                        clip: np.ndarray, \n",
    "                        model, \n",
    "                        threshold=0.5):\n",
    "    audios = []\n",
    "    y = clip.astype(np.float32)\n",
    "    len_y = len(y)\n",
    "    start = 0\n",
    "    end = CFG.period * CFG.sample_rate\n",
    "    while True:\n",
    "        y_batch = y[start:end].astype(np.float32)\n",
    "        if len(y_batch) != CFG.period * CFG.sample_rate:\n",
    "            y_pad = np.zeros(CFG.period * CFG.sample_rate, dtype=np.float32)\n",
    "            y_pad[:len(y_batch)] = y_batch\n",
    "            audios.append(y_pad)\n",
    "            break\n",
    "        start = end\n",
    "        end += CFG.period * CFG.sample_rate\n",
    "        audios.append(y_batch)\n",
    "        \n",
    "    array = np.asarray(audios)\n",
    "    tensors = torch.from_numpy(array)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    estimated_event_list = []\n",
    "    global_time = 0.0\n",
    "    for image in tqdm(tensors):\n",
    "        image = image.view(1, image.size(0))\n",
    "        image = image.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image)\n",
    "            framewise_outputs = prediction[\"framewise_output\"].detach(\n",
    "                ).cpu().numpy()[0]\n",
    "                \n",
    "        thresholded = framewise_outputs >= threshold\n",
    "\n",
    "        for target_idx in range(thresholded.shape[1]):\n",
    "            if thresholded[:, target_idx].mean() == 0:\n",
    "                pass\n",
    "            else:\n",
    "                detected = np.argwhere(thresholded[:, target_idx]).reshape(-1)\n",
    "                head_idx = 0\n",
    "                tail_idx = 0\n",
    "                while True:\n",
    "                    if (tail_idx + 1 == len(detected)) or (\n",
    "                            detected[tail_idx + 1] - \n",
    "                            detected[tail_idx] != 1):\n",
    "                        onset = 0.01 * detected[\n",
    "                            head_idx] + global_time\n",
    "                        offset = 0.01 * detected[\n",
    "                            tail_idx] + global_time\n",
    "                        onset_idx = detected[head_idx]\n",
    "                        offset_idx = detected[tail_idx]\n",
    "                        max_confidence = framewise_outputs[\n",
    "                            onset_idx:offset_idx, target_idx].max()\n",
    "                        mean_confidence = framewise_outputs[\n",
    "                            onset_idx:offset_idx, target_idx].mean()\n",
    "                        estimated_event = {\n",
    "                            \"audio_id\": audio_id,\n",
    "                            \"ebird_code\": CFG.target_columns[target_idx],\n",
    "                            \"onset\": onset,\n",
    "                            \"offset\": offset,\n",
    "                            \"max_confidence\": max_confidence,\n",
    "                            \"mean_confidence\": mean_confidence\n",
    "                        }\n",
    "                        estimated_event_list.append(estimated_event)\n",
    "                        head_idx = tail_idx + 1\n",
    "                        tail_idx = tail_idx + 1\n",
    "                        if head_idx >= len(detected):\n",
    "                            break\n",
    "                    else:\n",
    "                        tail_idx += 1\n",
    "        global_time += CFG.period\n",
    "        \n",
    "    prediction_df = pd.DataFrame(estimated_event_list)\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccc8ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_df,\n",
    "               weights_path: Path,\n",
    "               threshold=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TimmSED(\n",
    "        base_model_name=CFG.base_model_name,\n",
    "        pretrained=CFG.pretrained,\n",
    "        num_classes=CFG.num_classes,\n",
    "        in_channels=CFG.in_channels)\n",
    "#     model = prepare_model_for_inference(model, weights_path).to(device)\n",
    "    checkpoint = torch.load(weights_path)\n",
    "    Learner(model).load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for i, audio_path in enumerate(test_df['path']):\n",
    "        clip, _ = sf.read(audio_path)\n",
    "        \n",
    "        prediction_df = prediction_for_clip(test_df['row_id'][i],\n",
    "                                            clip=clip,\n",
    "                                            model=model,\n",
    "                                            threshold=threshold)\n",
    "\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ad25964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 82.79it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.92it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.82it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 83.03it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.84it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.90it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.88it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.77it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.84it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.93it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.95it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.93it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.86it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.73it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.71it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.62it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 81.85it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 82.77it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 85.07it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 85.15it/s]\n"
     ]
    }
   ],
   "source": [
    "weights_path = Path(\"./output/TimmSED-0-0.ckpt\")\n",
    "submission = prediction(test_df=submission_df,\n",
    "                        weights_path=weights_path,\n",
    "                        threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84d5eeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_id</th>\n",
       "      <th>ebird_code</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>max_confidence</th>\n",
       "      <th>mean_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>sonspa</td>\n",
       "      <td>83.13</td>\n",
       "      <td>84.05</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.551175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>sonspa</td>\n",
       "      <td>88.75</td>\n",
       "      <td>89.37</td>\n",
       "      <td>0.554120</td>\n",
       "      <td>0.546856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>cangoo</td>\n",
       "      <td>247.82</td>\n",
       "      <td>252.19</td>\n",
       "      <td>0.626601</td>\n",
       "      <td>0.564994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>cangoo</td>\n",
       "      <td>260.31</td>\n",
       "      <td>261.24</td>\n",
       "      <td>0.539445</td>\n",
       "      <td>0.533091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>cangoo</td>\n",
       "      <td>263.76</td>\n",
       "      <td>264.05</td>\n",
       "      <td>0.501531</td>\n",
       "      <td>0.501531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28933_SSW</td>\n",
       "      <td>cangoo</td>\n",
       "      <td>270.32</td>\n",
       "      <td>271.25</td>\n",
       "      <td>0.525225</td>\n",
       "      <td>0.516478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21767_COR</td>\n",
       "      <td>whiwre1</td>\n",
       "      <td>548.13</td>\n",
       "      <td>549.06</td>\n",
       "      <td>0.573237</td>\n",
       "      <td>0.564815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26746_COR</td>\n",
       "      <td>bobfly1</td>\n",
       "      <td>47.51</td>\n",
       "      <td>49.06</td>\n",
       "      <td>0.598068</td>\n",
       "      <td>0.564776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26746_COR</td>\n",
       "      <td>bobfly1</td>\n",
       "      <td>125.01</td>\n",
       "      <td>125.93</td>\n",
       "      <td>0.510687</td>\n",
       "      <td>0.507044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7019_COR</td>\n",
       "      <td>grhowl</td>\n",
       "      <td>60.94</td>\n",
       "      <td>61.56</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>0.535390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7019_COR</td>\n",
       "      <td>grhowl</td>\n",
       "      <td>69.07</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.577757</td>\n",
       "      <td>0.548226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44957_COR</td>\n",
       "      <td>grekis</td>\n",
       "      <td>100.00</td>\n",
       "      <td>112.19</td>\n",
       "      <td>0.820388</td>\n",
       "      <td>0.620952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44957_COR</td>\n",
       "      <td>bobfly1</td>\n",
       "      <td>388.76</td>\n",
       "      <td>389.69</td>\n",
       "      <td>0.565416</td>\n",
       "      <td>0.534425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44957_COR</td>\n",
       "      <td>bobfly1</td>\n",
       "      <td>407.51</td>\n",
       "      <td>410.31</td>\n",
       "      <td>0.639545</td>\n",
       "      <td>0.584338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44957_COR</td>\n",
       "      <td>bobfly1</td>\n",
       "      <td>410.63</td>\n",
       "      <td>411.56</td>\n",
       "      <td>0.543118</td>\n",
       "      <td>0.531318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51010_SSW</td>\n",
       "      <td>bkcchi</td>\n",
       "      <td>580.94</td>\n",
       "      <td>582.18</td>\n",
       "      <td>0.516041</td>\n",
       "      <td>0.507153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>51010_SSW</td>\n",
       "      <td>bkcchi</td>\n",
       "      <td>587.19</td>\n",
       "      <td>590.32</td>\n",
       "      <td>0.719978</td>\n",
       "      <td>0.652645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51010_SSW</td>\n",
       "      <td>bkcchi</td>\n",
       "      <td>591.26</td>\n",
       "      <td>592.50</td>\n",
       "      <td>0.680634</td>\n",
       "      <td>0.638738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     audio_id ebird_code   onset  offset  max_confidence  mean_confidence\n",
       "0   28933_SSW     sonspa   83.13   84.05        0.578757         0.551175\n",
       "1   28933_SSW     sonspa   88.75   89.37        0.554120         0.546856\n",
       "2   28933_SSW     cangoo  247.82  252.19        0.626601         0.564994\n",
       "3   28933_SSW     cangoo  260.31  261.24        0.539445         0.533091\n",
       "4   28933_SSW     cangoo  263.76  264.05        0.501531         0.501531\n",
       "5   28933_SSW     cangoo  270.32  271.25        0.525225         0.516478\n",
       "6   21767_COR    whiwre1  548.13  549.06        0.573237         0.564815\n",
       "7   26746_COR    bobfly1   47.51   49.06        0.598068         0.564776\n",
       "8   26746_COR    bobfly1  125.01  125.93        0.510687         0.507044\n",
       "9    7019_COR     grhowl   60.94   61.56        0.535407         0.535390\n",
       "10   7019_COR     grhowl   69.07   69.99        0.577757         0.548226\n",
       "11  44957_COR     grekis  100.00  112.19        0.820388         0.620952\n",
       "12  44957_COR    bobfly1  388.76  389.69        0.565416         0.534425\n",
       "13  44957_COR    bobfly1  407.51  410.31        0.639545         0.584338\n",
       "14  44957_COR    bobfly1  410.63  411.56        0.543118         0.531318\n",
       "15  51010_SSW     bkcchi  580.94  582.18        0.516041         0.507153\n",
       "16  51010_SSW     bkcchi  587.19  590.32        0.719978         0.652645\n",
       "17  51010_SSW     bkcchi  591.26  592.50        0.680634         0.638738"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75408348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = submission[submission['offset'] - submission['onset'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fc46553",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "for audio_id, sub_df in submission.groupby(\"audio_id\"):\n",
    "    events = sub_df[[\"ebird_code\", \"onset\", \"offset\", \"max_confidence\"]].values\n",
    "    n_events = len(events)\n",
    "\n",
    "    for i in range(n_events):\n",
    "        event = events[i][0]\n",
    "        onset = events[i][1]\n",
    "        offset = events[i][2]\n",
    "\n",
    "        start_section = int((onset // 5) * 5) + 5\n",
    "        end_section = int((offset // 5) * 5) + 5\n",
    "        cur_section = start_section\n",
    "\n",
    "        row_id = f\"{audio_id}_{start_section}\"\n",
    "        if labels.get(row_id) is not None:\n",
    "            labels[row_id].add(event)\n",
    "        else:\n",
    "            labels[row_id] = set()\n",
    "            labels[row_id].add(event)\n",
    "\n",
    "        while cur_section != end_section:\n",
    "            cur_section += 5\n",
    "            row_id = f\"{audio_id}_{cur_section}\"\n",
    "            if labels.get(row_id) is not None:\n",
    "                labels[row_id].add(event)\n",
    "            else:\n",
    "                labels[row_id] = set()\n",
    "                labels[row_id].add(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b85b7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in labels:\n",
    "    labels[key] = \" \".join(sorted(list(labels[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7534ba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21767_COR_550</td>\n",
       "      <td>whiwre1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26746_COR_50</td>\n",
       "      <td>bobfly1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26746_COR_130</td>\n",
       "      <td>bobfly1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28933_SSW_85</td>\n",
       "      <td>sonspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28933_SSW_90</td>\n",
       "      <td>sonspa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          row_id    birds\n",
       "0  21767_COR_550  whiwre1\n",
       "1   26746_COR_50  bobfly1\n",
       "2  26746_COR_130  bobfly1\n",
       "3   28933_SSW_85   sonspa\n",
       "4   28933_SSW_90   sonspa"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ids = list(labels.keys())\n",
    "birds = list(labels.values())\n",
    "post_processed = pd.DataFrame({\n",
    "    \"row_id\": row_ids,\n",
    "    \"birds\": birds\n",
    "})\n",
    "post_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9c2a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_raws = []\n",
    "for audio_path in submission_df['path']:\n",
    "#         with timer(f\"Loading {str(audio_path)}\", logger):\n",
    "    seconds = []\n",
    "    row_ids = []\n",
    "    for second in range(5, 605, 5):\n",
    "        row_id = \"_\".join(audio_path.name.split(\"_\")[:2]) + f\"_{second}\"\n",
    "        seconds.append(second)\n",
    "        row_ids.append(row_id)\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"row_id\": row_ids,\n",
    "        \"seconds\": seconds\n",
    "    })\n",
    "    sub_raws.append(test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "559496fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_raws = pd.concat(sub_raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05f78372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57610_COR_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57610_COR_10</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57610_COR_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57610_COR_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57610_COR_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57610_COR_30</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57610_COR_35</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57610_COR_40</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57610_COR_45</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57610_COR_50</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57610_COR_55</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57610_COR_60</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57610_COR_65</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57610_COR_70</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>57610_COR_75</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57610_COR_80</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57610_COR_85</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>57610_COR_90</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>57610_COR_95</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57610_COR_100</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id   birds\n",
       "0     57610_COR_5  nocall\n",
       "1    57610_COR_10  nocall\n",
       "2    57610_COR_15  nocall\n",
       "3    57610_COR_20  nocall\n",
       "4    57610_COR_25  nocall\n",
       "5    57610_COR_30  nocall\n",
       "6    57610_COR_35  nocall\n",
       "7    57610_COR_40  nocall\n",
       "8    57610_COR_45  nocall\n",
       "9    57610_COR_50  nocall\n",
       "10   57610_COR_55  nocall\n",
       "11   57610_COR_60  nocall\n",
       "12   57610_COR_65  nocall\n",
       "13   57610_COR_70  nocall\n",
       "14   57610_COR_75  nocall\n",
       "15   57610_COR_80  nocall\n",
       "16   57610_COR_85  nocall\n",
       "17   57610_COR_90  nocall\n",
       "18   57610_COR_95  nocall\n",
       "19  57610_COR_100  nocall"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_row_id = sub_raws[[\"row_id\"]]\n",
    "submission = all_row_id.merge(post_processed, on=\"row_id\", how=\"left\")\n",
    "submission = submission.fillna(\"nocall\")\n",
    "submission.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30d90a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6395833333333261\n"
     ]
    }
   ],
   "source": [
    "if not SUBMISSION and not TEST:\n",
    "    sys.path.append('../../')\n",
    "    import src.row_wise_micro_averaged_f1 as mi_f1\n",
    "    \n",
    "    submission = pd.read_csv(OUTPUT_DIR / \"submission.csv\")\n",
    "    ans = pd.read_csv(MAIN_DATA_DIR / 'train_soundscape_labels.csv')\n",
    "    \n",
    "    submission = pd.merge(submission, ans, how='inner', on='row_id')\n",
    "    \n",
    "    f1_score = mi_f1.row_wise_micro_averaged_f1_score(list(submission['birds_y']), list(submission['birds_x']))\n",
    "    print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5ac57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
